{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee7364e",
   "metadata": {},
   "source": [
    "to do: \n",
    "    objectif mÃ©tier \n",
    "    1) une classe( mÃ¨re) abstraite record (load) â†’ (class enfant) to_csv qui rÃ©cup le df â†’ pour l'enregistrer en CSV\n",
    "    2) une classe ( mÃ¨re) abstraite obj_client â†’(classe enfant)  ville, station , record  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c162a7",
   "metadata": {},
   "source": [
    "Imperatif avant la prochaine seance:\n",
    "    -EXTRACTION des donnÃ©es\n",
    "    - IntÃ©gration des donnÃ©es dans diffÃ©rents ModÃ¨les ( ex: Station & Record)\n",
    "\n",
    "Avant le 25/11/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "301224cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extractors.meteo_toulouse_extractor import MeteoToulouseExtractor\n",
    "from extractors.meteo_toulouse_extractor import MeteoToulouseExtractor\n",
    "from validators.dataframe_validator import DataFrameValidator\n",
    "import pandas as pd \n",
    "from abc import ABC, abstractmethod\n",
    "from extractors.stations_config import STATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc31c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transform(ABC):\n",
    "    \"\"\" Classe abstraite pour avoir plusieurs possibilitÃ©s de transform\"\"\" \n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform(self):\n",
    "        \"\"\"MÃ©thode de transform Ã  implÃ©menter\"\"\"\n",
    "        pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8fb6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "class CsvTransform:\n",
    "    \"\"\"Transformation/validation/sauvegarde d'un DataFrame en CSV.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, station: str):\n",
    "        self.df = df.copy()\n",
    "        self.station = station\n",
    "\n",
    "    def validate(self):\n",
    "        #Appelle validateur\n",
    "        DataFrameValidator.validate(self.df)\n",
    "        print(f\"Donnees valides pour {self.station} ({len(self.df)} lignes)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_df(station: str) -> pd.DataFrame:\n",
    "    \"\"\"Extrait et valide les donnÃ©es d'une station donnÃ©e.\"\"\"\n",
    "    extractor = MeteoToulouseExtractor(station)\n",
    "    data_json = extractor.extract()\n",
    "    df = extractor.to_dataframe(data_json)\n",
    "\n",
    "    # Validation simple\n",
    "    try:\n",
    "        DataFrameValidator.validate(df)\n",
    "        print(f\"âœ… DonnÃ©es valides pour {station} ({len(df)} lignes)\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Erreur dans la validation de {station} :\", e)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def merge_all_stations() -> pd.DataFrame:\n",
    "    \"\"\"ConcatÃ¨ne les DataFrames de toutes les stations disponibles.\"\"\"\n",
    "    list_df = []\n",
    "\n",
    "    for station in STATIONS.keys():\n",
    "        try:\n",
    "            print(f\"ğŸ” Extraction en cours pour : {station}\")\n",
    "            df_station = load_data_df(station)\n",
    "\n",
    "            # Ajout d'une colonne pour identifier la station dans la fusion\n",
    "            df_station[\"station_name\"] = station\n",
    "\n",
    "            list_df.append(df_station)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur pour {station} â†’ pas grave, on continue ({e})\")\n",
    "\n",
    "    # Fusionner toutes les stations sans erreur\n",
    "    if list_df:\n",
    "        df_final = pd.concat(list_df, ignore_index=True)\n",
    "        print(f\"\\nğŸ¯ Fusion terminÃ©e : {len(df_final)} lignes au total.\")\n",
    "        return df_final\n",
    "    else:\n",
    "        print(\"ğŸš« Aucune donnÃ©e nâ€™a pu Ãªtre extraite.\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22055668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Extraction en cours pour : montaudran\n",
      "âœ… DonnÃ©es valides pour montaudran (96 lignes)\n",
      "ğŸ” Extraction en cours pour : colomiers_zi_enjacca\n",
      "âœ… DonnÃ©es valides pour colomiers_zi_enjacca (95 lignes)\n",
      "ğŸ” Extraction en cours pour : parc_maourine\n",
      "âœ… DonnÃ©es valides pour parc_maourine (88 lignes)\n",
      "ğŸ” Extraction en cours pour : marengo\n",
      "âŒ Erreur pour marengo â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 2-station-meteo-toulouse-marengo does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : pech_david\n",
      "âœ… DonnÃ©es valides pour pech_david (78 lignes)\n",
      "ğŸ” Extraction en cours pour : compans_cafarelli\n",
      "âœ… DonnÃ©es valides pour compans_cafarelli (96 lignes)\n",
      "ğŸ” Extraction en cours pour : fondeyre\n",
      "âœ… DonnÃ©es valides pour fondeyre (14 lignes)\n",
      "ğŸ” Extraction en cours pour : paul_sabatier\n",
      "âœ… DonnÃ©es valides pour paul_sabatier (92 lignes)\n",
      "ğŸ” Extraction en cours pour : mondouzil\n",
      "âš ï¸  Erreur dans la validation de mondouzil : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : basso_cambo\n",
      "âŒ Erreur pour basso_cambo â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 8-station-meteo-toulouse-basso-cambo does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : soupetard\n",
      "âœ… DonnÃ©es valides pour soupetard (14 lignes)\n",
      "ğŸ” Extraction en cours pour : mons_epuration\n",
      "âœ… DonnÃ©es valides pour mons_epuration (2 lignes)\n",
      "ğŸ” Extraction en cours pour : saint_jory_beldou\n",
      "âœ… DonnÃ©es valides pour saint_jory_beldou (9 lignes)\n",
      "ğŸ” Extraction en cours pour : jardin_des_plantes\n",
      "âŒ Erreur pour jardin_des_plantes â†’ pas grave, on continue (Erreur API 400: {\n",
      "  \"error_code\": \"ODSQLError\",\n",
      "  \"message\": \"ODSQL query is malformed: Unknown field: heure_de_paris. Clause(s) containing the error(s): select.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : la_machine_af\n",
      "âš ï¸  Erreur dans la validation de la_machine_af : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : life_marechal_juin\n",
      "âŒ Erreur pour life_marechal_juin â†’ pas grave, on continue (Erreur API 400: {\n",
      "  \"error_code\": \"ODSQLError\",\n",
      "  \"message\": \"ODSQL query is malformed: Unknown field: heure_de_paris. Clause(s) containing the error(s): select.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : metropole\n",
      "âŒ Erreur pour metropole â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 1-station-meteo-toulouse-metropole does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : mondonville_ecole\n",
      "âš ï¸  Erreur dans la validation de mondonville_ecole : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : teso\n",
      "âš ï¸  Erreur dans la validation de teso : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : zi_thibaud\n",
      "âš ï¸  Erreur dans la validation de zi_thibaud : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : busca\n",
      "âŒ Erreur pour busca â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 3-station-meteo-toulouse-busca does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : pibrac_bouconne\n",
      "âš ï¸  Erreur dans la validation de pibrac_bouconne : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : life_hall1\n",
      "âŒ Erreur pour life_hall1 â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 5-station-meteo-toulouse-life-hall-1 does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : nakache\n",
      "âŒ Erreur pour nakache â†’ pas grave, on continue (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 5-station-meteo-toulouse-nakache does not exist.\"\n",
      "})\n",
      "ğŸ” Extraction en cours pour : casselardit\n",
      "âš ï¸  Erreur dans la validation de casselardit : Le DataFrame est vide\n",
      "ğŸ” Extraction en cours pour : st_exupery\n",
      "âš ï¸  Erreur dans la validation de st_exupery : Le DataFrame est vide\n",
      "\n",
      "ğŸ¯ Fusion terminÃ©e : 584 lignes au total.\n"
     ]
    }
   ],
   "source": [
    "df = merge_all_stations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0366f7",
   "metadata": {},
   "source": [
    "Point d'amÃ©lioration, si la data Ã©xiste dejas ne la rajoute pas au CSV\n",
    "Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b034b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data_meteo_toulouse_station/data_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e58ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e737df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ DÃ©marrage de la transformation (ALL stations)...\n",
      "ğŸ“¡ Extraction en cours pour : montaudran\n",
      "ğŸ“¡ Extraction en cours pour : colomiers_zi_enjacca\n",
      "ğŸ“¡ Extraction en cours pour : parc_maourine\n",
      "ğŸ“¡ Extraction en cours pour : marengo\n",
      "âš ï¸ Erreur pour marengo â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 2-station-meteo-toulouse-marengo does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : pech_david\n",
      "ğŸ“¡ Extraction en cours pour : compans_cafarelli\n",
      "ğŸ“¡ Extraction en cours pour : fondeyre\n",
      "ğŸ“¡ Extraction en cours pour : paul_sabatier\n",
      "ğŸ“¡ Extraction en cours pour : mondouzil\n",
      "âš ï¸ Erreur pour mondouzil â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : basso_cambo\n",
      "âš ï¸ Erreur pour basso_cambo â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 8-station-meteo-toulouse-basso-cambo does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : soupetard\n",
      "ğŸ“¡ Extraction en cours pour : mons_epuration\n",
      "ğŸ“¡ Extraction en cours pour : saint_jory_beldou\n",
      "ğŸ“¡ Extraction en cours pour : jardin_des_plantes\n",
      "âš ï¸ Erreur pour jardin_des_plantes â†’ ignorÃ©e (Erreur API 400: {\n",
      "  \"error_code\": \"ODSQLError\",\n",
      "  \"message\": \"ODSQL query is malformed: Unknown field: heure_de_paris. Clause(s) containing the error(s): select.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : la_machine_af\n",
      "âš ï¸ Erreur pour la_machine_af â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : life_marechal_juin\n",
      "âš ï¸ Erreur pour life_marechal_juin â†’ ignorÃ©e (Erreur API 400: {\n",
      "  \"error_code\": \"ODSQLError\",\n",
      "  \"message\": \"ODSQL query is malformed: Unknown field: heure_de_paris. Clause(s) containing the error(s): select.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : metropole\n",
      "âš ï¸ Erreur pour metropole â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 1-station-meteo-toulouse-metropole does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : mondonville_ecole\n",
      "âš ï¸ Erreur pour mondonville_ecole â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : teso\n",
      "âš ï¸ Erreur pour teso â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : zi_thibaud\n",
      "âš ï¸ Erreur pour zi_thibaud â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : busca\n",
      "âš ï¸ Erreur pour busca â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 3-station-meteo-toulouse-busca does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : pibrac_bouconne\n",
      "âš ï¸ Erreur pour pibrac_bouconne â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : life_hall1\n",
      "âš ï¸ Erreur pour life_hall1 â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 5-station-meteo-toulouse-life-hall-1 does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : nakache\n",
      "âš ï¸ Erreur pour nakache â†’ ignorÃ©e (Erreur API 404: {\n",
      "  \"error_code\": \"NotFoundResource\",\n",
      "  \"message\": \"The requested dataset 5-station-meteo-toulouse-nakache does not exist.\"\n",
      "})\n",
      "ğŸ“¡ Extraction en cours pour : casselardit\n",
      "âš ï¸ Erreur pour casselardit â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "ğŸ“¡ Extraction en cours pour : st_exupery\n",
      "âš ï¸ Erreur pour st_exupery â†’ ignorÃ©e (Le DataFrame est vide)\n",
      "\n",
      "ğŸ¯ Fusion terminÃ©e : 585 lignes au total.\n",
      "ğŸ’¾ Nouveau fichier crÃ©Ã© : data_meteo_toulouse_station\\data_all_stations.csv (585 lignes)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    transform = CsvTransform()\n",
    "    df_all = transform.transform()   \n",
    "    transform.save_to_csv()          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
